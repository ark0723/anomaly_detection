{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8948e368-e9b3-442c-8a3a-453f1b4a3836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mount_path = \"/mnt/datamount\"\n",
    "dbutils.fs.ls(mount_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd6d1680-61ce-486f-8269-b7487b77d87f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Image Augmentation\n",
    "- problem: class imblance between 'abnomal' and 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68879ba3-681b-4aac-b234-9d2805cfd724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('parquet').load(f'{mount_path}/images_final')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad6a9fb-c42f-410a-a3fa-0bcbfbeb3bca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.groupBy('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a72dc2-f18a-4e55-a2be-3e77061c0b36",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TEST: Augment Anomalies"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import pandas_udf, col, lit, regexp_replace\n",
    "from pyspark.sql.types import BinaryType\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@pandas_udf(BinaryType())\n",
    "def transpose_img_udf(df_series):\n",
    "    def transpose(img_bytes):\n",
    "        '''Transpose image and serialize back as jpeg.'''\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        transpose_types = ['horizontal', 'vertical', 'rotate_90', 'rotate_180','rotate_270', 'squash&skew']\n",
    "\n",
    "        # squach & skew matrix\n",
    "        w, h = img.size\n",
    "        ss_matrix = (1, 0.3, -w*0.15, 0.3, 1, -h*0.15)\n",
    "\n",
    "        # # transpose will be applied randomly from 1 to 3 times for an image.\n",
    "        selected = random.sample(transpose_types, random.randint(1, 3))\n",
    "        # selected = ['squash&skew']\n",
    "                                 \n",
    "        for selected_tr in selected:\n",
    "            match selected_tr:\n",
    "                case 'horizontal':\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                case 'vertical':\n",
    "                    img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                case 'rotate_90':\n",
    "                    img = img.transpose(Image.ROTATE_90)    \n",
    "                case 'rotate_180':\n",
    "                    img = img.transpose(Image.ROTATE_180)   \n",
    "                case 'rotate_270':\n",
    "                    img = img.transpose(Image.ROTATE_270)  \n",
    "                case 'squash&skew':\n",
    "                    img = img.transform((w,h), Image.AFFINE, ss_matrix)\n",
    "        # save back as jpeg\n",
    "        output = io.BytesIO()\n",
    "        img.save(output, format='JPEG')\n",
    "        return output.getvalue()\n",
    "    return df_series.apply(transpose)\n",
    "\n",
    "# define image metadata\n",
    "img_meta = {\n",
    "    \"spark.contentAnnotation\":'{\"mimeType\":\"image/jpeg\"}'\n",
    "}\n",
    "# apply the UDF to transpose images randomly with multiple transpose types\n",
    "noisy_transposed_df = df.filter(col('label') == 'noise').withColumn('image', transpose_img_udf('image').alias('image', metadata = img_meta)).withColumn('name', regexp_replace(col('name'), '.jpg', '_transposed')).withColumn('path', lit('N/A'))\n",
    "display(noisy_transposed_df)\n",
    "display(df.filter(col('label') == 'noise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d69a5750-b053-4a8e-9e31-e225d52120bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Augment Anomalies"
    }
   },
   "outputs": [],
   "source": [
    "# generate multiple df_transposed DataFrames\n",
    "num_to_apply = 5\n",
    "transposed_dfs = []\n",
    "\n",
    "for i in range(num_to_apply):\n",
    "    transposed_df = df.filter(col('label') == 'noise').withColumn('image', transpose_img_udf('image').alias('image', metadata = img_meta)).withColumn('name', regexp_replace(col('name'), '.jpg', '_tr')).withColumn('path', lit('N/A'))\n",
    "    transposed_dfs.append(transposed_df)\n",
    "\n",
    "# combine all transposed_dfs\n",
    "transposed_df = reduce(DataFrame.unionAll, transposed_dfs)\n",
    "display(transposed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dce22ff9-58c2-4e77-bb96-6bb2374af11e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "salt and pepper patches"
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf(BinaryType())\n",
    "def add_salt_pepper_patches_udf(df_series):\n",
    "    def add_salt_pepper_patches(img_bytes):\n",
    "        \"\"\"Add salt and pepper patches to image and serialize back as jpeg.\"\"\"\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        patch_pixels = 500\n",
    "        noise_value = 255 # white\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        w, h = img.size\n",
    "\n",
    "        # radius r\n",
    "        r = int(np.sqrt(patch_pixels) / np.pi)\n",
    "        r = max(r, 5)\n",
    "\n",
    "        # random center point for the noise patch\n",
    "        cx = np.random.randint(r, w - r)\n",
    "        cy = np.random.randint(r, h - r)\n",
    "\n",
    "        num_points = np.random.randint(5,10) # polygon points between 5 and 10\n",
    "        angles = np.linspace(0, 2*np.pi, num_points, endpoint=False)\n",
    "        angles += np.random.uniform(0, 2*np.pi/num_points, size = num_points)\n",
    "        radii = np.random.uniform(0.5*r, 1.5*r, size = num_points)\n",
    "        points = [\n",
    "            (int(cx + r*np.cos(angle)), int(cy + r*np.sin(angle)))\n",
    "            for angle, randius in zip(angles, radii)\n",
    "        ]\n",
    "\n",
    "        fill_color = (noise_value,) * 3 if img.mode == 'RGB' else noise_value\n",
    "        draw.polygon(points, fill_color)\n",
    "\n",
    "        output = io.BytesIO()\n",
    "        img.save(output, format='JPEG')\n",
    "\n",
    "        return output.getvalue()\n",
    "    return df_series.apply(add_salt_pepper_patches)\n",
    "\n",
    "salt_pepper_df = df.filter(col('label') == 'surfing').withColumn('image', add_salt_pepper_patches_udf('image').alias('image', metadata = img_meta)).withColumn('name', regexp_replace(col('name'),r\"(\\d+)\", r\"$1_add_noise\")).withColumn('path', lit('N/A'))\n",
    "display(salt_pepper_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de3fbd58-4696-4a53-a7b1-2df5b4541830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_augmentation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
