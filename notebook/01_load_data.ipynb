{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5153a52-7c09-4741-b302-2fb23013ef25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mount_path = \"/mnt/datamount\"\n",
    "dbutils.fs.ls(mount_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fd326af-e878-4c3f-852b-47ba653b23ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a9a9712-07e7-41b6-9908-42348136d6f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aa3b689-f3f9-4b4a-817b-4559b3b21492",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Images"
    }
   },
   "outputs": [],
   "source": [
    "def create_file_info_df(imgs_dir: str):\n",
    "    full_path = f\"{mount_path}/{imgs_dir}\"\n",
    "    try:\n",
    "        files = dbutils.fs.ls(full_path)\n",
    "    except Exception:\n",
    "        raise Exception(f\"Directory {full_path} does not exist\")\n",
    "        return None\n",
    "\n",
    "    file_info_list = [{\"path\": file.path, \"name\": file.name} for file in files]\n",
    "    return spark.createDataFrame(file_info_list)\n",
    "\n",
    "file_info_df = create_file_info_df(\"images\")\n",
    "\n",
    "# file_info_df: remove extension from 'name' column\n",
    "file_info_df = file_info_df.withColumn(\n",
    "    \"name\",\n",
    "    regexp_replace(\"name\", \"\\\\.[^.]+$\", \"\")\n",
    ")\n",
    "display(file_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2f2b8a-270e-49ce-a0fe-332f5a7f2f98",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Labels"
    }
   },
   "outputs": [],
   "source": [
    "label_files = dbutils.fs.ls(f\"{mount_path}/labels\") # list of all files in the directory\n",
    "label_path = label_files[0].path\n",
    "label_df = spark.read.csv(label_path, header = True, inferSchema = True)\n",
    "display(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7144e05f-cd48-44c0-bbf3-99057ad94e9f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761279739783}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "label_df = label_df.withColumnRenamed(\"img_name\", \"name\")\n",
    "label_df = label_df.withColumnRenamed(\"sports_activity\", \"label\")\n",
    "display(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39b4951c-17f0-42b9-8ab2-21a3d6785f38",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761279799141}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Join df: images and labels"
    }
   },
   "outputs": [],
   "source": [
    "# join the two dataframes with the 'name' column\n",
    "joined_df = file_info_df.join(\n",
    "    label_df,\n",
    "    on = \"name\",\n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ce4712-b2b4-4a69-a0dd-3a6265f94d4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Image Display"
    }
   },
   "outputs": [],
   "source": [
    "def display_image(df, sample_size: int = 5, keep_order = True):\n",
    "    \"\"\"\n",
    "    Display sample images from a Spark DataFrame containing image file paths.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Spark DataFrame with at least 'path' and 'name' columns.\n",
    "        sample_size (int): Number of images to display.\n",
    "        keep_order (bool): If True, display the first N images in order.\n",
    "                           If False, display N random images.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays images using matplotlib.\n",
    "    \"\"\"\n",
    "    if keep_order:\n",
    "        images = df.take(sample_size) # Get the first N rows as a list.\n",
    "    else:\n",
    "        # Get N random rows as a list.\n",
    "        # df.orderBy(F.rand()).limit(sample_size) : dataframe -> not callable\n",
    "        images = df.orderBy(F.rand()).limit(sample_size).collect()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, row in enumerate(images):\n",
    "        # Replace \"dbfs:/\" with \"/dbfs/\" for local file access in Databricks.\n",
    "        # why? FileNotFoundError: [Errno 2] No such file or directory: '/Workspace/Users/ark0723@gmail.com/anomaly_detection/notebook/dbfs:/mnt/datamount/images/frame_0.jpg' \n",
    "        img_path = row.path.replace(\"dbfs:/\", \"/dbfs/\")\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, sample_size, i+1)\n",
    "        plt.title(row.name)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960f6056-44c7-4705-99e9-d128821c0b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_image(joined_df, sample_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfddeaeb-b540-4aea-bcd2-aba4225a5c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_load_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
